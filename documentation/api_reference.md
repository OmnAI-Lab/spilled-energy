# API Reference

This document provides detailed information about the modules and functions available in the **Spilled Energy** library.

## `spilled_energy.generation`

### `generate_answer`
Generates text using a causal language model and returns associated logits.

```python
def generate_answer(
    prompt: str,
    model: PreTrainedModel,
    tokenizer: PreTrainedTokenizer,
    max_new_tokens: int = 100,
    do_sample: bool = False,
    temperature: float = 1.0,
    top_p: float = 1.0,
    device: str = "cuda",
) -> dict
```

- **Arguments**:
    - `prompt`: The input text prompt.
    - `model`: Loaded Hugging Face model instance.
    - `tokenizer`: Associated tokenizer.
    - `max_new_tokens`: Maximum tokens to generate (default: 100).
    - `do_sample`: Whether to use sampling (default: False).
    - `device`: Device to run generation on (default: "cuda").

- **Returns**: A dictionary containing:
    - `text`: Generated answer string.
    - `sequences`: Tensor of token IDs.
    - `scores`: Tuple of logits tensors for each step.

---

## `spilled_energy.extraction`

### `extract_exact_answer`
Extracts a specific short answer from a longer generated response using a model-based approach.

```python
def extract_exact_answer(
    question: str,
    long_answer: str,
    model: PreTrainedModel,
    tokenizer: PreTrainedTokenizer,
    example_template: str = None,
    device: str = "cuda",
) -> str
```

- **Arguments**:
    - `question`: The original question asked.
    - `long_answer`: The verbose answer generated by the model.
    - `model`: Model to use for extraction (can be same as generation model).
    - `tokenizer`: Tokenizer for the extraction model.
    - `example_template`: Optional custom prompt template for extraction.

- **Returns**: String containing the extracted exact answer (or "NO ANSWER").

---

## `spilled_energy.energy`

This module contains the core mathematical functions for Spilled Energy.

### `spilled_energy`
Computes Spilled Energy ($E_\Delta$), Marginal Energy ($E_{margin}$), and Energy ($E$) for a sequence of tokens.

```python
def spilled_energy(
    logits: List[List[List[float]]],
    ids: List[List[int]],
    beta: float = 1.0,
    prompt_length: int = 0,
) -> tuple
```

- **Arguments**:
    - `logits`: List of logits for the sequence (nested list structure).
    - `ids`: List of token IDs for the sequence.
    - `beta`: Temperature scaling factor (inverse temperature).
    - `prompt_length`: Number of initial tokens to exclude from calculation.

- **Returns**: Tuple `(delta, E_margin, E)`, where each element is a list of values per token.

### `spilled_energy_torch`
A PyTorch-optimized version of `spilled_energy` for batch processing.

```python
def spilled_energy_torch(
    logits: torch.Tensor,
    ids: torch.Tensor,
    beta: float = 1.0,
    pad_token_id: int = -100
) -> tuple
```

- **Arguments**:
    - `logits`: Tensor of shape `[batch, seq_len, vocab_size]`.
    - `ids`: Tensor of shape `[batch, seq_len]`.

- **Returns**: Tuple of tensors `(delta, E_margin, E)`.

---

## `spilled_energy.model`

### `load_model_and_tokenizer`
Helper utility to load models with appropriate configurations.

```python
def load_model_and_tokenizer(
    model_name: str,
    device: Optional[str] = None,
    dtype: str = "float16",
    trust_remote_code: bool = True,
    quantization_config: Optional[BitsAndBytesConfig] = None,
) -> Tuple[AutoModelForCausalLM, AutoTokenizer]
```

- **Arguments**:
    - `model_name`: Hugging Face model ID.
    - `device`: "cuda", "cpu", or None (auto).
    - `dtype`: "float16", "float32", or "bfloat16".
    - `quantization_config`: Config for loading quantized models (e.g. bitsandbytes).

- **Returns**: Tuple of `(model, tokenizer)`.

---

## `spilled_energy.utils`

Contains various helpers, including plotting functions.

### `compute_metrics`
Aggregates raw energy values into statistical metrics.

```python
def compute_metrics(results: list) -> Dict[str, float]
```

- **Returns**: Dictionary with `mean`, `std`, `median`, `min`, `max` of spilled energy values.

### Plotting Functions
- `plot_tokens`: Visualizes token-level energy values by color-coding text.
- `plot_histogram`: Plots distribution of energy values for correct vs. incorrect answers.
- `plot_ROC_curve`: Plots Receiver Operating Characteristic curve.
- `plot_PR_curve`: Plots Precision-Recall curve.
